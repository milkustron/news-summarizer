{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "iARr22tGf_rb",
    "ExecuteTime": {
     "end_time": "2024-12-29T17:18:38.646788Z",
     "start_time": "2024-12-29T17:18:16.467431Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:18:38.658850Z",
     "start_time": "2024-12-29T17:18:38.654792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by removing unnecessary tokens.\"\"\"\n",
    "    return text.strip()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:19:13.287586Z",
     "start_time": "2024-12-29T17:18:50.844669Z"
    }
   },
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "# Select the ones you want\n",
    "df = df[['text','summary']]\n",
    "df = df.sample(frac=1/3, random_state=42) # taking only 1/3 because whole set is taking about 48hours to train\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text  \\\n",
       "146201  MISSISSAUGA, Ontario, June 4 -- Qayyum Abdul J...   \n",
       "468184  Welcome to Apartment Life, an online discussio...   \n",
       "109069  The biggest traffic jam likely to occur during...   \n",
       "267027  1. Conventional wisdom has taken such a beatin...   \n",
       "239711  Bravo's \"Project Runway,\" which begins its thi...   \n",
       "\n",
       "                                                  summary  \n",
       "146201  MISSISSAUGA, Ontario, June 4 -- Qayyum Abdul J...  \n",
       "468184  Welcome to Apartment Life, an online discussio...  \n",
       "109069  The biggest traffic jam likely to occur during...  \n",
       "267027  By Staff Writer Dan Balz What will it take to ...  \n",
       "239711  Search Washington, DC area TV schedules and re...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146201</th>\n",
       "      <td>MISSISSAUGA, Ontario, June 4 -- Qayyum Abdul J...</td>\n",
       "      <td>MISSISSAUGA, Ontario, June 4 -- Qayyum Abdul J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468184</th>\n",
       "      <td>Welcome to Apartment Life, an online discussio...</td>\n",
       "      <td>Welcome to Apartment Life, an online discussio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109069</th>\n",
       "      <td>The biggest traffic jam likely to occur during...</td>\n",
       "      <td>The biggest traffic jam likely to occur during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267027</th>\n",
       "      <td>1. Conventional wisdom has taken such a beatin...</td>\n",
       "      <td>By Staff Writer Dan Balz What will it take to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239711</th>\n",
       "      <td>Bravo's \"Project Runway,\" which begins its thi...</td>\n",
       "      <td>Search Washington, DC area TV schedules and re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XsIozTi8WmQA",
    "ExecuteTime": {
     "end_time": "2024-12-29T10:30:19.966057Z",
     "start_time": "2024-12-29T10:10:43.557474Z"
    }
   },
   "source": [
    "# Step 2: Tokenization and Dataset Preparation\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"summary\"],\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Split dataset\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/156260 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "453a1c67fd5d4992a66d4f6e08919223"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ice1s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T10:30:44.192624Z",
     "start_time": "2024-12-29T10:30:43.365558Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_dataset.save_to_disk(\"tokenized_data\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/5 shards):   0%|          | 0/156260 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba26a77567214be7af10c79d472f4651"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T10:30:45.169250Z",
     "start_time": "2024-12-29T10:30:45.024076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_dataset = Dataset.load_from_disk(\"tokenized_data\")\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T10:30:48.306784Z",
     "start_time": "2024-12-29T10:30:46.637226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T10:34:21.415269Z",
     "start_time": "2024-12-29T10:34:21.358622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 4: Fine-Tuning the Model\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # Output directory\n",
    "    eval_strategy=\"epoch\",    # Evaluation strategy\n",
    "    learning_rate=5e-5,              # Learning rate\n",
    "    per_device_train_batch_size=12,   # Batch size\n",
    "    per_device_eval_batch_size=12,    # Evaluation batch size\n",
    "    num_train_epochs=3,              # Number of epochs\n",
    "    weight_decay=0.01,               # Weight decay\n",
    "    save_total_limit=1,              # Limit on saved checkpoints\n",
    "    logging_dir=\"./logs\",           # Directory for logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True,  # Enable mixed precision\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ice1s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:18:18.870664Z",
     "start_time": "2024-12-29T10:34:22.619061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Step 5: Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./fine_tuned_bart\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_bart\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ice1s\\AppData\\Local\\Temp\\ipykernel_30668\\1522660895.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31254' max='31254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31254/31254 4:43:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.062466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.044154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ice1s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bart\\\\tokenizer_config.json',\n",
       " './fine_tuned_bart\\\\special_tokens_map.json',\n",
       " './fine_tuned_bart\\\\vocab.json',\n",
       " './fine_tuned_bart\\\\merges.txt',\n",
       " './fine_tuned_bart\\\\added_tokens.json')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:27:30.305299Z",
     "start_time": "2024-12-29T17:27:27.923414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def summarize_text(text, trained_model):\n",
    "    \"\"\"Generate a summary for the given text.\"\"\"\n",
    "    inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    summary_ids = trained_model.generate(inputs[\"input_ids\"], max_length=128, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    print(\"Generated summary IDs:\", summary_ids)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(\"./fine_tuned_bart\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"./fine_tuned_bart\", use_safetensors=True).to(device)\n",
    "\n",
    "sample = df.sample(1).iloc[0]\n",
    "sample_text = sample[\"text\"]\n",
    "\n",
    "generated_summary = summarize_text(sample.text, model)\n",
    "print(\"Generated Summary:\", generated_summary)\n",
    "print(\"Original summary:\", sample['summary'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ice1s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\bart\\configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ice1s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\utils.py:1527: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary IDs: tensor([[    2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0, 25887,  9752,\n",
      "          1238,  3710,  4585,     9,    45,   519,    22, 18062,    62,     7,\n",
      "            49,  9061,     7,  1157,   162,     7,   109, 24821,   173,    89,\n",
      "           113,    25,     5,  1546,   585,    39,  5824,    71,    10,  3550,\n",
      "            12,   180,   756,     4,     2]], device='cuda:0')\n",
      "Generated Summary: Dan Rather accused CBS executives of not having \"lived up to their obligation to allow me to do substantive work there\" as the network announced his departure after a 44-year career.\n",
      "Original summary: Dan Rather accused CBS executives of not having \"lived up to their obligation to allow me to do substantive work there\" as the network announced his departure after a 44-year career.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
